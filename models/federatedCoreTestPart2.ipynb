{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[31m  Could not find a version that satisfies the requirement tensorflow~=2.11.0 (from tensorflow-federated) (from versions: 0.12.0, 0.12.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.3.0, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.9.0, 1.10.0, 1.10.1, 1.11.0, 1.12.0, 1.12.2, 1.12.3, 1.13.1, 1.13.2, 1.14.0)\u001b[0m\n",
      "\u001b[31mNo matching distribution found for tensorflow~=2.11.0 (from tensorflow-federated)\u001b[0m\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/usr/lib/python2.7/site-packages/pip/commands/install.py\", line 326, in run\n",
      "    strip_file_prefix=options.strip_file_prefix,\n",
      "  File \"/usr/lib/python2.7/site-packages/pip/req/req_set.py\", line 742, in install\n",
      "    **kwargs\n",
      "  File \"/usr/lib/python2.7/site-packages/pip/req/req_install.py\", line 834, in install\n",
      "    strip_file_prefix=strip_file_prefix\n",
      "  File \"/usr/lib/python2.7/site-packages/pip/req/req_install.py\", line 1037, in move_wheel_files\n",
      "    strip_file_prefix=strip_file_prefix,\n",
      "  File \"/usr/lib/python2.7/site-packages/pip/wheel.py\", line 346, in move_wheel_files\n",
      "    clobber(source, lib_dir, True)\n",
      "  File \"/usr/lib/python2.7/site-packages/pip/wheel.py\", line 317, in clobber\n",
      "    ensure_dir(destdir)\n",
      "  File \"/usr/lib/python2.7/site-packages/pip/utils/__init__.py\", line 83, in ensure_dir\n",
      "    os.makedirs(path)\n",
      "  File \"/usr/lib64/python2.7/os.py\", line 157, in makedirs\n",
      "    mkdir(name, mode)\n",
      "OSError: [Errno 13] Permission denied: '/usr/lib64/python2.7/site-packages/UNKNOWN-0.0.0.dist-info'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade tensorflow-federated\n",
    "!pip install --quiet --upgrade nest-asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pyfhel import Pyfhel, PyCtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 22:46:02.840403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 22:46:03.023751: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-04 22:46:03.079773: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-04 22:46:04.488388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-04 22:46:04.488469: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-04 22:46:04.488479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "# Must use the Python context because it\n",
    "# supports tff.sequence_* intrinsics.\n",
    "executor_factory = tff.framework.local_executor_factory(\n",
    "    support_sequence_ops=True)\n",
    "execution_context = tff.framework.ExecutionContext(\n",
    "    executor_fn=executor_factory)\n",
    "tff.framework.set_default_context(execution_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HEmatmult(a, b):\n",
    "    return np.matmul(a, b)\n",
    "\n",
    "def HEreduce_mean(a, axis=None):\n",
    "    if axis is None:\n",
    "        return np.sum(a)/a.size\n",
    "    return np.sum(a, axis=axis)/a.shape[axis]\n",
    "\n",
    "def HEreduce_sum(a, axis=None):\n",
    "    return np.sum(a, axis=axis)\n",
    "\n",
    "def HEexp(a, n=4):\n",
    "    d = 1.0\n",
    "    rt = 0.0\n",
    "    for i in range(n):\n",
    "        rt += d/np.math.factorial(i)\n",
    "        d = a*d\n",
    "    return rt\n",
    "\n",
    "def HEsquare(a):\n",
    "    return a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 22:46:12.369683: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-04 22:46:12.369730: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-04 22:46:12.370354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tff.federated_computation\n",
    "def hello_world():\n",
    "  return 'Hello, World!'\n",
    "\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist_train, mnist_test = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.dtype, x.shape) for x in mnist_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en1 = Pyfhel(context_params={'scheme':'ckks', 'n':2**14, 'scale':2**30, 'qi_sizes':[30]*5})\n",
    "en1.keyGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_PER_USER = 1000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "\n",
    "def get_data_for_digit(source, digit):\n",
    "  output_sequence = []\n",
    "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
    "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
    "    batch_samples = all_samples[i:i + BATCH_SIZE]\n",
    "    output_sequence.append({\n",
    "        'x':\n",
    "            np.array([en1.encrypt(source[0][i].flatten() / 255.0) for i in batch_samples],\n",
    "                     dtype=PyCtxt),\n",
    "        'y':\n",
    "            np.array([en1.encrypt(source[1][i]) for i in batch_samples], dtype=PyCtxt)\n",
    "    })\n",
    "  return output_sequence\n",
    "\n",
    "\n",
    "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]\n",
    "\n",
    "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated_train_data[5][-1]['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28, 28), cmap='gray')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<x=float32[?,784],y=int32[?]>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weights=float32[784,10],bias=float32[10]>\n"
     ]
    }
   ],
   "source": [
    "MODEL_SPEC = collections.OrderedDict(\n",
    "    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
    "    bias=tf.TensorSpec(shape=[10], dtype=tf.float32))\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "print(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: `forward_pass` is defined separately from `batch_loss` so that it can \n",
    "# be later called from within another tf.function. Necessary because a\n",
    "# @tf.function  decorated method cannot invoke a @tff.tf_computation.\n",
    "\n",
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "  predicted_y = HEsquare(\n",
    "      HEmatmult(batch['x'], model['weights']) + model['bias'])\n",
    "  return -HEreduce_mean(\n",
    "      HEreduce_sum(\n",
    "          tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "  return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<model=<weights=float32[784,10],bias=float32[10]>,batch=<x=float32[?,784],y=int32[?]>> -> float32)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_loss.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_model = collections.OrderedDict(\n",
    "    weights=np.zeros([784, 10], dtype=np.float32),\n",
    "    bias=np.zeros([10], dtype=np.float32))\n",
    "\n",
    "sample_batch = federated_train_data[5][-1]\n",
    "\n",
    "batch_loss(initial_model, sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "  # Define a group of model variables and set them to `initial_model`. Must\n",
    "  # be defined outside the @tf.function.\n",
    "  model_vars = collections.OrderedDict([\n",
    "      (name, tf.Variable(name=name, initial_value=value))\n",
    "      for name, value in initial_model.items()\n",
    "  ])\n",
    "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "  @tf.function\n",
    "  def _train_on_batch(model_vars, batch):\n",
    "    # Perform one step of gradient descent using loss from `batch_loss`.\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss = forward_pass(model_vars, batch)\n",
    "    grads = tape.gradient(loss, model_vars)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "    return model_vars\n",
    "\n",
    "  return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<initial_model=<weights=float32[784,10],bias=float32[10]>,batch=<x=float32[?,784],y=int32[?]>,learning_rate=float32> -> <weights=float32[784,10],bias=float32[10]>)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_train.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initial_model\n",
    "losses = []\n",
    "for _ in range(5):\n",
    "  model = batch_train(model, sample_batch, 0.1)\n",
    "  losses.append(batch_loss(model, sample_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39846364, 0.25261888, 0.19375294, 0.16018456, 0.1380317]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "\n",
    "  @tff.tf_computation(LOCAL_DATA_TYPE, tf.float32)\n",
    "  def _insert_learning_rate_to_sequence(dataset, learning_rate):\n",
    "    return dataset.map(lambda x: (x, learning_rate))\n",
    "\n",
    "  batches_with_learning_rate = _insert_learning_rate_to_sequence(all_batches, learning_rate)\n",
    "\n",
    "  # Mapping function to apply to each batch.\n",
    "  @tff.federated_computation(MODEL_TYPE, batches_with_learning_rate.type_signature.element)\n",
    "  def batch_fn(model, batch_with_lr):\n",
    "    batch, lr = batch_with_lr\n",
    "    return batch_train(model, batch, lr)\n",
    "\n",
    "  return tff.sequence_reduce(batches_with_learning_rate, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<initial_model=<weights=float32[784,10],bias=float32[10]>,learning_rate=float32,all_batches=<x=float32[?,784],y=int32[?]>*> -> <weights=float32[784,10],bias=float32[10]>)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(local_train.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "locally_trained_model = local_train(initial_model, 0.1, federated_train_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "\n",
    "  @tff.tf_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "  def _insert_model_to_sequence(model, dataset):\n",
    "    return dataset.map(lambda x: (model, x))\n",
    "\n",
    "  model_plus_data = _insert_model_to_sequence(model, all_batches)\n",
    "\n",
    "  @tff.tf_computation(tf.float32, batch_loss.type_signature.result)\n",
    "  def tff_add(accumulator, arg):\n",
    "    return accumulator + arg\n",
    "\n",
    "  return tff.sequence_reduce(\n",
    "      tff.sequence_map(\n",
    "          batch_loss,\n",
    "          model_plus_data), 0., tff_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<model=<weights=float32[784,10],bias=float32[10]>,all_batches=<x=float32[?,784],y=int32[?]>*> -> float32)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(local_eval.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_model loss = 23.025854\n",
      "locally_trained_model loss = 0.8081478\n"
     ]
    }
   ],
   "source": [
    "print('initial_model loss =', local_eval(initial_model,\n",
    "                                         federated_train_data[5]))\n",
    "print('locally_trained_model loss =',\n",
    "      local_eval(locally_trained_model, federated_train_data[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_model loss = 23.025854\n",
      "locally_trained_model loss = 79.414024\n"
     ]
    }
   ],
   "source": [
    "print('initial_model loss =', local_eval(initial_model,\n",
    "                                         federated_train_data[0]))\n",
    "print('locally_trained_model loss =',\n",
    "      local_eval(locally_trained_model, federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_MODEL_TYPE = tff.type_at_server(MODEL_TYPE)\n",
    "CLIENT_DATA_TYPE = tff.type_at_clients(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
    "def federated_eval(model, data):\n",
    "  return tff.federated_mean(\n",
    "      tff.federated_map(local_eval, [tff.federated_broadcast(model),  data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_model loss = 23.025852\n",
      "locally_trained_model loss = 83.617744\n"
     ]
    }
   ],
   "source": [
    "print('initial_model loss =', federated_eval(initial_model,\n",
    "                                             federated_train_data))\n",
    "print('locally_trained_model loss =',\n",
    "      federated_eval(locally_trained_model, federated_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_FLOAT_TYPE = tff.type_at_server(tf.float32)\n",
    "\n",
    "\n",
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,\n",
    "                           CLIENT_DATA_TYPE)\n",
    "def federated_train(model, learning_rate, data):\n",
    "  # Perform federated averaging here\n",
    "  return tff.federated_mean(\n",
    "      tff.federated_map(local_train, [\n",
    "          tff.federated_broadcast(model),\n",
    "          tff.federated_broadcast(learning_rate), data\n",
    "      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0, loss=20.691389083862305\n",
      "round 1, loss=19.161178588867188\n",
      "round 2, loss=17.984769821166992\n",
      "round 3, loss=17.064708709716797\n",
      "round 4, loss=16.326141357421875\n"
     ]
    }
   ],
   "source": [
    "model = initial_model\n",
    "learning_rate = 0.1\n",
    "for round_num in range(5):\n",
    "  model = federated_train(model, learning_rate, federated_train_data)\n",
    "  learning_rate = learning_rate * 0.9\n",
    "  loss = federated_eval(model, federated_train_data)\n",
    "  print('round {}, loss={}'.format(round_num, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_model test loss = 23.025852\n",
      "trained_model test loss = 16.38777\n"
     ]
    }
   ],
   "source": [
    "print('initial_model test loss =',\n",
    "      federated_eval(initial_model, federated_test_data))\n",
    "print('trained_model test loss =', federated_eval(model, federated_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('MLAI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd18e2703a944517b229c10d426dc40a3613b9589690a53834e185b69f2ae3d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
